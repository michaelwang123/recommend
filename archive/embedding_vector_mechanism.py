#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
IDåµŒå…¥å‘é‡è·å–æœºåˆ¶è¯¦è§£
è¯¦ç»†è§£é‡ŠåµŒå…¥å‘é‡æ˜¯å¦‚ä½•ä»IDè·å–çš„ï¼ŒåŒ…æ‹¬å†…éƒ¨å®ç°å’Œæ•°å­¦åŸç†
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from torch.nn import functional as F

plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class EmbeddingMechanismExplainer:
    def __init__(self):
        self.n_users = 10
        self.embedding_dim = 4  # ä¸ºäº†æ¼”ç¤ºä½¿ç”¨å°ç»´åº¦
        self.n_devices = 8
        
    def explain_lookup_table_concept(self):
        """è§£é‡ŠæŸ¥æ‰¾è¡¨æ¦‚å¿µ"""
        print("ğŸ“‹ åµŒå…¥å±‚çš„æœ¬è´¨ï¼šæŸ¥æ‰¾è¡¨")
        print("=" * 80)
        
        print("ğŸ” æ ¸å¿ƒæ¦‚å¿µï¼šåµŒå…¥å±‚å®é™…ä¸Šæ˜¯ä¸€ä¸ªå¯å­¦ä¹ çš„æŸ¥æ‰¾è¡¨")
        print()
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„åµŒå…¥å±‚ç”¨äºæ¼”ç¤º
        user_embedding = nn.Embedding(self.n_users, self.embedding_dim)
        
        print("åµŒå…¥å±‚å†…éƒ¨ç»“æ„ï¼š")
        print("-" * 40)
        print("```")
        print(f"ç”¨æˆ·æ•°é‡: {self.n_users}")
        print(f"åµŒå…¥ç»´åº¦: {self.embedding_dim}")
        print(f"åµŒå…¥çŸ©é˜µå½¢çŠ¶: [{self.n_users}, {self.embedding_dim}]")
        print("```")
        
        # æ˜¾ç¤ºåµŒå…¥çŸ©é˜µ
        embedding_matrix = user_embedding.weight.data
        print(f"\nåµŒå…¥çŸ©é˜µå†…å®¹ï¼ˆå®é™…å‚æ•°ï¼‰:")
        print("-" * 40)
        
        print("ç”¨æˆ·ID | åµŒå…¥å‘é‡ (4ç»´)")
        print("-------|" + "-" * 40)
        for i in range(self.n_users):
            vector = embedding_matrix[i].numpy()
            vector_str = f"[{vector[0]:6.3f}, {vector[1]:6.3f}, {vector[2]:6.3f}, {vector[3]:6.3f}]"
            print(f"ç”¨æˆ·{i:2d}  | {vector_str}")
        
        print(f"\nğŸ’¡ å…³é”®ç†è§£ï¼š")
        print("â€¢ åµŒå…¥å±‚å°±æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œæ¯è¡Œå¯¹åº”ä¸€ä¸ªç”¨æˆ·çš„å‘é‡")
        print("â€¢ é€šè¿‡ç”¨æˆ·IDç›´æ¥ç´¢å¼•çŸ©é˜µçš„å¯¹åº”è¡Œ")
        print("â€¢ è¿™äº›å‘é‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šä¸æ–­æ›´æ–°")
        
        return user_embedding, embedding_matrix
    
    def demonstrate_indexing_process(self):
        """æ¼”ç¤ºç´¢å¼•è¿‡ç¨‹"""
        print(f"\nğŸ” ç´¢å¼•è¿‡ç¨‹è¯¦è§£")
        print("=" * 80)
        
        user_embedding = nn.Embedding(self.n_users, self.embedding_dim)
        embedding_matrix = user_embedding.weight.data
        
        print("æ­¥éª¤1ï¼šå‡†å¤‡ç”¨æˆ·IDè¾“å…¥")
        print("-" * 30)
        user_ids = torch.tensor([0, 2, 5, 7])
        print(f"è¾“å…¥ç”¨æˆ·ID: {user_ids.tolist()}")
        print(f"Tensorå½¢çŠ¶: {user_ids.shape}")
        
        print(f"\næ­¥éª¤2ï¼šé€šè¿‡åµŒå…¥å±‚è·å–å‘é‡")
        print("-" * 30)
        print("```python")
        print("user_vectors = user_embedding(user_ids)")
        print("```")
        
        user_vectors = user_embedding(user_ids)
        print(f"è¾“å‡ºå½¢çŠ¶: {user_vectors.shape}")
        
        print(f"\næ­¥éª¤3ï¼šæŸ¥çœ‹å…·ä½“çš„ç´¢å¼•è¿‡ç¨‹")
        print("-" * 30)
        
        for i, user_id in enumerate(user_ids):
            manual_vector = embedding_matrix[user_id]
            auto_vector = user_vectors[i]
            
            print(f"ç”¨æˆ·ID {user_id}:")
            print(f"  æ‰‹åŠ¨ç´¢å¼•: {manual_vector.numpy()}")
            print(f"  åµŒå…¥å±‚è¾“å‡º: {auto_vector.detach().numpy()}")
            print(f"  æ˜¯å¦ç›¸åŒ: {torch.allclose(manual_vector, auto_vector)}")
            print()
        
        print("ğŸ¯ ç´¢å¼•åŸç†ï¼š")
        print("user_embedding(user_id) â‰ˆ embedding_matrix[user_id]")
        print("æœ¬è´¨ä¸Šå°±æ˜¯çŸ©é˜µçš„è¡Œç´¢å¼•æ“ä½œ")
        
        return user_ids, user_vectors
    
    def show_mathematical_details(self):
        """å±•ç¤ºæ•°å­¦ç»†èŠ‚"""
        print(f"\nğŸ“ æ•°å­¦åŸç†è¯¦è§£")
        print("=" * 80)
        
        print("ğŸ”¢ One-Hotç¼–ç è§†è§’ï¼š")
        print("-" * 30)
        
        user_id = 3
        one_hot = torch.zeros(self.n_users)
        one_hot[user_id] = 1
        
        print(f"ç”¨æˆ·ID: {user_id}")
        print(f"One-Hotå‘é‡: {one_hot.numpy()}")
        
        # åˆ›å»ºåµŒå…¥çŸ©é˜µ
        user_embedding = nn.Embedding(self.n_users, self.embedding_dim)
        W = user_embedding.weight.data
        
        print(f"\nåµŒå…¥çŸ©é˜µ W å½¢çŠ¶: {W.shape}")
        print("W =")
        for i in range(W.shape[0]):
            print(f"  [{W[i, 0].item():6.3f}, {W[i, 1].item():6.3f}, {W[i, 2].item():6.3f}, {W[i, 3].item():6.3f}]")
        
        print(f"\nğŸ§® çŸ©é˜µä¹˜æ³•è®¡ç®—ï¼š")
        print("-" * 30)
        
        # æ–¹æ³•1ï¼šOne-hotçŸ©é˜µä¹˜æ³•
        result_matmul = torch.matmul(one_hot, W)
        
        # æ–¹æ³•2ï¼šç›´æ¥ç´¢å¼•
        result_index = W[user_id]
        
        # æ–¹æ³•3ï¼šåµŒå…¥å±‚
        result_embedding = user_embedding(torch.tensor([user_id]))[0]
        
        print(f"æ–¹æ³•1 (One-Hot Ã— W): {result_matmul.numpy()}")
        print(f"æ–¹æ³•2 (ç›´æ¥ç´¢å¼•):     {result_index.numpy()}")
        print(f"æ–¹æ³•3 (åµŒå…¥å±‚):      {result_embedding.detach().numpy()}")
        
        print(f"\næ•°å­¦å…¬å¼ï¼š")
        print("user_vector = one_hot_vector Ã— W")
        print("å…¶ä¸­ï¼š")
        print(f"  one_hot_vector.shape = [1, {self.n_users}]")
        print(f"  W.shape = [{self.n_users}, {self.embedding_dim}]")
        print(f"  user_vector.shape = [1, {self.embedding_dim}]")
        
        print(f"\nâš¡ ä¼˜åŒ–ï¼š")
        print("å®é™…å®ç°ä¸­ï¼ŒPyTorchè·³è¿‡One-Hotç¼–ç ï¼Œç›´æ¥ä½¿ç”¨ç´¢å¼•")
        print("è¿™æ ·æ›´é«˜æ•ˆï¼Œé¿å…äº†ç¨€ç–çŸ©é˜µä¹˜æ³•")
        
        return W, one_hot, result_matmul
    
    def demonstrate_gradient_flow(self):
        """æ¼”ç¤ºæ¢¯åº¦æµåŠ¨"""
        print(f"\nğŸ”„ æ¢¯åº¦æ›´æ–°æœºåˆ¶")
        print("=" * 80)
        
        print("ğŸ¯ è®­ç»ƒè¿‡ç¨‹ä¸­åµŒå…¥å‘é‡å¦‚ä½•æ›´æ–°ï¼š")
        print("-" * 40)
        
        # åˆ›å»ºç®€å•çš„æ¨èæ¨¡å‹
        class SimpleRecommendModel(nn.Module):
            def __init__(self, n_users, n_devices, embed_dim):
                super().__init__()
                self.user_embedding = nn.Embedding(n_users, embed_dim)
                self.device_embedding = nn.Embedding(n_devices, embed_dim)
                
            def forward(self, user_ids, device_ids):
                user_vectors = self.user_embedding(user_ids)
                device_vectors = self.device_embedding(device_ids)
                
                # è®¡ç®—ç›¸ä¼¼åº¦å¾—åˆ†
                scores = torch.sum(user_vectors * device_vectors, dim=1)
                return scores
        
        model = SimpleRecommendModel(self.n_users, self.n_devices, self.embedding_dim)
        
        print("æ¨¡å‹ç»“æ„:")
        print("```python")
        print("user_vectors = user_embedding(user_ids)")
        print("device_vectors = device_embedding(device_ids)")
        print("scores = sum(user_vectors * device_vectors)")
        print("```")
        
        # è®°å½•åˆå§‹å‚æ•°
        initial_user_embedding = model.user_embedding.weight.data.clone()
        
        print(f"\nåˆå§‹ç”¨æˆ·0çš„åµŒå…¥å‘é‡:")
        print(f"{initial_user_embedding[0].numpy()}")
        
        # æ¨¡æ‹Ÿä¸€æ¬¡è®­ç»ƒæ­¥éª¤
        print(f"\nğŸš€ æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤ï¼š")
        print("-" * 30)
        
        user_ids = torch.tensor([0, 1, 2])
        device_ids = torch.tensor([0, 1, 2])
        target_scores = torch.tensor([1.0, 0.0, 1.0])  # çœŸå®æ ‡ç­¾
        
        # å‰å‘ä¼ æ’­
        predicted_scores = model(user_ids, device_ids)
        
        # è®¡ç®—æŸå¤±
        loss = F.mse_loss(predicted_scores, target_scores)
        
        print(f"è¾“å…¥: ç”¨æˆ·{user_ids.tolist()}, è®¾å¤‡{device_ids.tolist()}")
        print(f"é¢„æµ‹å¾—åˆ†: {predicted_scores.detach().numpy()}")
        print(f"çœŸå®å¾—åˆ†: {target_scores.numpy()}")
        print(f"æŸå¤±: {loss.item():.4f}")
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        print(f"\nğŸ“Š æ¢¯åº¦ä¿¡æ¯ï¼š")
        print("-" * 20)
        user_grad = model.user_embedding.weight.grad
        print(f"ç”¨æˆ·0åµŒå…¥å‘é‡çš„æ¢¯åº¦: {user_grad[0].numpy()}")
        
        # å‚æ•°æ›´æ–°
        lr = 0.1
        with torch.no_grad():
            model.user_embedding.weight -= lr * model.user_embedding.weight.grad
        
        updated_user_embedding = model.user_embedding.weight.data
        print(f"\næ›´æ–°åç”¨æˆ·0çš„åµŒå…¥å‘é‡:")
        print(f"{updated_user_embedding[0].numpy()}")
        
        change = updated_user_embedding[0] - initial_user_embedding[0]
        print(f"å˜åŒ–é‡: {change.numpy()}")
        print(f"æ›´æ–°å…¬å¼: new_embedding = old_embedding - lr * gradient")
        
        return model, initial_user_embedding, updated_user_embedding
    
    def show_batch_processing(self):
        """å±•ç¤ºæ‰¹å¤„ç†"""
        print(f"\nğŸ”„ æ‰¹å¤„ç†æœºåˆ¶")
        print("=" * 80)
        
        user_embedding = nn.Embedding(self.n_users, self.embedding_dim)
        
        print("ğŸ¯ å•ä¸ªç”¨æˆ· vs æ‰¹é‡ç”¨æˆ·å¤„ç†ï¼š")
        print("-" * 40)
        
        # å•ä¸ªç”¨æˆ·
        single_user_id = torch.tensor([3])
        single_result = user_embedding(single_user_id)
        
        print(f"å•ä¸ªç”¨æˆ·å¤„ç†:")
        print(f"  è¾“å…¥: {single_user_id.tolist()}")
        print(f"  è¾“å…¥å½¢çŠ¶: {single_user_id.shape}")
        print(f"  è¾“å‡ºå½¢çŠ¶: {single_result.shape}")
        print(f"  è¾“å‡º: {single_result.detach().numpy()}")
        
        # æ‰¹é‡ç”¨æˆ·
        batch_user_ids = torch.tensor([0, 3, 5, 7])
        batch_result = user_embedding(batch_user_ids)
        
        print(f"\næ‰¹é‡ç”¨æˆ·å¤„ç†:")
        print(f"  è¾“å…¥: {batch_user_ids.tolist()}")
        print(f"  è¾“å…¥å½¢çŠ¶: {batch_user_ids.shape}")
        print(f"  è¾“å‡ºå½¢çŠ¶: {batch_result.shape}")
        print(f"  è¾“å‡º:")
        for i, user_id in enumerate(batch_user_ids):
            print(f"    ç”¨æˆ·{user_id}: {batch_result[i].detach().numpy()}")
        
        print(f"\nâš¡ æ‰¹å¤„ç†ä¼˜åŠ¿ï¼š")
        print("â€¢ GPUå¹¶è¡Œå¤„ç†å¤šä¸ªç”¨æˆ·")
        print("â€¢ æé«˜è®­ç»ƒæ•ˆç‡")
        print("â€¢ å……åˆ†åˆ©ç”¨ç¡¬ä»¶èµ„æº")
        
        return single_result, batch_result
    
    def compare_implementation_methods(self):
        """å¯¹æ¯”ä¸åŒå®ç°æ–¹æ³•"""
        print(f"\nğŸ”§ ä¸åŒå®ç°æ–¹æ³•å¯¹æ¯”")
        print("=" * 80)
        
        user_ids = torch.tensor([1, 3, 5])
        
        print("æ–¹æ³•å¯¹æ¯”ï¼ˆåŠŸèƒ½ç›¸åŒï¼Œæ•ˆç‡ä¸åŒï¼‰ï¼š")
        print("-" * 50)
        
        # æ–¹æ³•1ï¼šPyTorchåµŒå…¥å±‚ï¼ˆæ¨èï¼‰
        embedding_layer = nn.Embedding(self.n_users, self.embedding_dim)
        result1 = embedding_layer(user_ids)
        
        print("æ–¹æ³•1ï¼šPyTorchåµŒå…¥å±‚")
        print("```python")
        print("embedding = nn.Embedding(num_users, embed_dim)")
        print("result = embedding(user_ids)")
        print("```")
        print(f"ä¼˜ç‚¹: é«˜æ•ˆã€è‡ªåŠ¨æ¢¯åº¦ã€GPUä¼˜åŒ–")
        print(f"ç»“æœå½¢çŠ¶: {result1.shape}")
        
        # æ–¹æ³•2ï¼šæ‰‹åŠ¨æŸ¥æ‰¾è¡¨
        W = embedding_layer.weight.data
        result2 = W[user_ids]
        
        print(f"\næ–¹æ³•2ï¼šæ‰‹åŠ¨ç´¢å¼•")
        print("```python")
        print("W = embedding_matrix")
        print("result = W[user_ids]")
        print("```")
        print(f"ä¼˜ç‚¹: ç®€å•ç›´è§‚")
        print(f"ç¼ºç‚¹: æ‰‹åŠ¨å¤„ç†æ¢¯åº¦")
        print(f"ç»“æœå½¢çŠ¶: {result2.shape}")
        
        # æ–¹æ³•3ï¼šOne-Hot + çŸ©é˜µä¹˜æ³•ï¼ˆä¸æ¨èï¼‰
        one_hot_batch = torch.zeros(len(user_ids), self.n_users)
        for i, uid in enumerate(user_ids):
            one_hot_batch[i, uid] = 1
        result3 = torch.matmul(one_hot_batch, W)
        
        print(f"\næ–¹æ³•3ï¼šOne-HotçŸ©é˜µä¹˜æ³•")
        print("```python")
        print("one_hot = to_one_hot(user_ids)")
        print("result = one_hot @ embedding_matrix")
        print("```")
        print(f"ä¼˜ç‚¹: æ•°å­¦åŸç†æ¸…æ™°")
        print(f"ç¼ºç‚¹: å†…å­˜æ¶ˆè€—å¤§ã€è®¡ç®—ä½æ•ˆ")
        print(f"ç»“æœå½¢çŠ¶: {result3.shape}")
        
        # éªŒè¯ç»“æœä¸€è‡´æ€§
        print(f"\nâœ… ç»“æœéªŒè¯ï¼š")
        print(f"æ–¹æ³•1 vs æ–¹æ³•2: {torch.allclose(result1, result2)}")
        print(f"æ–¹æ³•1 vs æ–¹æ³•3: {torch.allclose(result1, result3)}")
        print(f"æ–¹æ³•2 vs æ–¹æ³•3: {torch.allclose(result2, result3)}")
        
        print(f"\nğŸ¯ æ¨èä½¿ç”¨ï¼š")
        print("âœ… PyTorch nn.Embedding - æœ€ä½³é€‰æ‹©")
        print("âš ï¸ æ‰‹åŠ¨ç´¢å¼• - è°ƒè¯•æ—¶å¯ç”¨")
        print("âŒ One-HotçŸ©é˜µä¹˜æ³• - é¿å…ä½¿ç”¨")
        
        return result1, result2, result3
    
    def demonstrate_memory_efficiency(self):
        """æ¼”ç¤ºå†…å­˜æ•ˆç‡"""
        print(f"\nğŸ’¾ å†…å­˜æ•ˆç‡åˆ†æ")
        print("=" * 80)
        
        large_n_users = 10000
        large_embed_dim = 64
        
        print("ğŸ” å¤§è§„æ¨¡åœºæ™¯åˆ†æï¼š")
        print("-" * 30)
        print(f"ç”¨æˆ·æ•°é‡: {large_n_users:,}")
        print(f"åµŒå…¥ç»´åº¦: {large_embed_dim}")
        
        # åµŒå…¥çŸ©é˜µå¤§å°
        embedding_params = large_n_users * large_embed_dim
        embedding_memory_mb = embedding_params * 4 / (1024 * 1024)  # float32
        
        print(f"\nåµŒå…¥çŸ©é˜µ:")
        print(f"  å‚æ•°æ•°é‡: {embedding_params:,}")
        print(f"  å†…å­˜å ç”¨: {embedding_memory_mb:.1f} MB")
        
        # æ‰¹å¤„ç†å†…å­˜
        batch_size = 512
        batch_memory_kb = batch_size * large_embed_dim * 4 / 1024
        
        print(f"\næ‰¹å¤„ç† (batch_size={batch_size}):")
        print(f"  è¾“å‡ºå¼ é‡å¤§å°: [{batch_size}, {large_embed_dim}]")
        print(f"  å†…å­˜å ç”¨: {batch_memory_kb:.1f} KB")
        
        # One-Hotæ–¹æ³•å†…å­˜ï¼ˆå¯¹æ¯”ï¼‰
        onehot_memory_mb = batch_size * large_n_users * 4 / (1024 * 1024)
        
        print(f"\nå¦‚æœä½¿ç”¨One-Hotæ–¹æ³•:")
        print(f"  One-HotçŸ©é˜µå¤§å°: [{batch_size}, {large_n_users}]")
        print(f"  å†…å­˜å ç”¨: {onehot_memory_mb:.1f} MB")
        print(f"  æ•ˆç‡æ¯”è¾ƒ: One-Hotæ˜¯åµŒå…¥å±‚çš„ {onehot_memory_mb/batch_memory_kb*1024:.0f}x å†…å­˜æ¶ˆè€—")
        
        print(f"\nğŸ’¡ å…³é”®ä¼˜åŠ¿ï¼š")
        print("â€¢ åµŒå…¥å±‚åªå­˜å‚¨å¿…è¦çš„å‚æ•°çŸ©é˜µ")
        print("â€¢ é¿å…äº†ç¨€ç–çš„One-Hotè¡¨ç¤º")
        print("â€¢ ç´¢å¼•æ“ä½œæ¯”çŸ©é˜µä¹˜æ³•æ›´é«˜æ•ˆ")
        
        return embedding_memory_mb, batch_memory_kb, onehot_memory_mb
    
    def create_visual_summary(self):
        """åˆ›å»ºå¯è§†åŒ–æ€»ç»“"""
        print(f"\nğŸ“Š å¯è§†åŒ–æ€»ç»“")
        print("=" * 80)
        
        print("IDåµŒå…¥å‘é‡è·å–æµç¨‹å›¾ï¼š")
        print("""
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   ç”¨æˆ·ID    â”‚â”€â”€â”€â–¶â”‚   åµŒå…¥å±‚    â”‚â”€â”€â”€â–¶â”‚  åµŒå…¥å‘é‡   â”‚
        â”‚   [0,1,2]   â”‚    â”‚  æŸ¥æ‰¾è¡¨æœºåˆ¶  â”‚    â”‚ [4Ã—64çŸ©é˜µ]  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ åµŒå…¥çŸ©é˜µW   â”‚
                         â”‚[10000Ã—64]   â”‚
                         â”‚å¯å­¦ä¹ å‚æ•°   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """)
        
        print("å…³é”®æ­¥éª¤ï¼š")
        print("1ï¸âƒ£ è¾“å…¥ï¼šç”¨æˆ·IDå¼ é‡ [batch_size]")
        print("2ï¸âƒ£ ç´¢å¼•ï¼šåœ¨åµŒå…¥çŸ©é˜µä¸­æŸ¥æ‰¾å¯¹åº”è¡Œ")
        print("3ï¸âƒ£ è¾“å‡ºï¼šåµŒå…¥å‘é‡ [batch_size, embed_dim]")
        print("4ï¸âƒ£ è®­ç»ƒï¼šé€šè¿‡åå‘ä¼ æ’­æ›´æ–°åµŒå…¥çŸ©é˜µ")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” IDåµŒå…¥å‘é‡è·å–æœºåˆ¶è¯¦è§£")
    print("=" * 80)
    
    explainer = EmbeddingMechanismExplainer()
    
    # 1. æŸ¥æ‰¾è¡¨æ¦‚å¿µ
    explainer.explain_lookup_table_concept()
    
    # 2. ç´¢å¼•è¿‡ç¨‹æ¼”ç¤º
    explainer.demonstrate_indexing_process()
    
    # 3. æ•°å­¦åŸç†
    explainer.show_mathematical_details()
    
    # 4. æ¢¯åº¦æ›´æ–°
    explainer.demonstrate_gradient_flow()
    
    # 5. æ‰¹å¤„ç†æœºåˆ¶
    explainer.show_batch_processing()
    
    # 6. å®ç°æ–¹æ³•å¯¹æ¯”
    explainer.compare_implementation_methods()
    
    # 7. å†…å­˜æ•ˆç‡
    explainer.demonstrate_memory_efficiency()
    
    # 8. å¯è§†åŒ–æ€»ç»“
    explainer.create_visual_summary()
    
    print(f"\n" + "=" * 80)
    print("ğŸ¯ æ ¸å¿ƒè¦ç‚¹æ€»ç»“:")
    print("â€¢ åµŒå…¥å±‚æœ¬è´¨æ˜¯å¯å­¦ä¹ çš„æŸ¥æ‰¾è¡¨")
    print("â€¢ é€šè¿‡ç”¨æˆ·IDç›´æ¥ç´¢å¼•åµŒå…¥çŸ©é˜µçš„å¯¹åº”è¡Œ")
    print("â€¢ æ¯”One-Hot+çŸ©é˜µä¹˜æ³•æ›´é«˜æ•ˆ")
    print("â€¢ åµŒå…¥å‘é‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€šè¿‡æ¢¯åº¦æ›´æ–°")
    print("â€¢ PyTorchè‡ªåŠ¨å¤„ç†æ‰¹å¤„ç†å’ŒGPUä¼˜åŒ–")
    print("=" * 80)

if __name__ == "__main__":
    main() 