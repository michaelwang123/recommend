#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€æ´ç‰ˆï¼šPyTorchç”¨æˆ·IDåµŒå…¥å‘é‡ç”Ÿæˆç¤ºä¾‹
å±•ç¤ºæ ¸å¿ƒä»£ç å’ŒåŸºæœ¬ç”¨æ³•
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

def basic_user_embedding_demo():
    """åŸºç¡€ç”¨æˆ·åµŒå…¥å‘é‡ç”Ÿæˆæ¼”ç¤º"""
    print("ğŸš€ åŸºç¡€ç”¨æˆ·åµŒå…¥å‘é‡ç”Ÿæˆæ¼”ç¤º")
    print("=" * 50)
    
    # 1. åˆ›å»ºç”¨æˆ·åµŒå…¥å±‚
    num_users = 1000      # ç”¨æˆ·æ€»æ•°
    embedding_dim = 64    # åµŒå…¥å‘é‡ç»´åº¦
    
    user_embedding = nn.Embedding(num_users, embedding_dim)
    
    print(f"âœ… åˆ›å»ºåµŒå…¥å±‚: {num_users} ç”¨æˆ· Ã— {embedding_dim} ç»´åº¦")
    print(f"   å‚æ•°æ•°é‡: {user_embedding.weight.numel():,}")
    print(f"   åµŒå…¥çŸ©é˜µå½¢çŠ¶: {user_embedding.weight.shape}")
    
    # 2. å•ä¸ªç”¨æˆ·IDåµŒå…¥
    user_id = torch.tensor([123])
    user_vector = user_embedding(user_id)
    
    print(f"\nğŸ” å•ä¸ªç”¨æˆ·åµŒå…¥ï¼š")
    print(f"   ç”¨æˆ·ID: {user_id.item()}")
    print(f"   åµŒå…¥å‘é‡å½¢çŠ¶: {user_vector.shape}")
    print(f"   å‘é‡å‰5ç»´: {user_vector[0][:5].detach().numpy()}")
    
    # 3. æ‰¹é‡ç”¨æˆ·IDåµŒå…¥
    user_ids = torch.tensor([10, 25, 50, 100])
    user_vectors = user_embedding(user_ids)
    
    print(f"\nğŸ“Š æ‰¹é‡ç”¨æˆ·åµŒå…¥ï¼š")
    print(f"   ç”¨æˆ·IDs: {user_ids.tolist()}")
    print(f"   åµŒå…¥å‘é‡å½¢çŠ¶: {user_vectors.shape}")
    
    for i, uid in enumerate(user_ids):
        print(f"   ç”¨æˆ·{uid.item():3d}: {user_vectors[i][:3].detach().numpy()}")
    
    # 4. è®¡ç®—ç”¨æˆ·ç›¸ä¼¼åº¦
    print(f"\nğŸ”— ç”¨æˆ·ç›¸ä¼¼åº¦è®¡ç®—ï¼š")
    user1_vec = user_vectors[0]  # ç”¨æˆ·10
    user2_vec = user_vectors[1]  # ç”¨æˆ·25
    
    similarity = torch.cosine_similarity(user1_vec, user2_vec, dim=0)
    print(f"   ç”¨æˆ·10 vs ç”¨æˆ·25 ç›¸ä¼¼åº¦: {similarity.item():.4f}")
    
    return user_embedding

def training_embedding_demo():
    """è®­ç»ƒè¿‡ç¨‹ä¸­çš„åµŒå…¥å‘é‡æ›´æ–°æ¼”ç¤º"""
    print(f"\nğŸ“ è®­ç»ƒè¿‡ç¨‹æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºç®€å•çš„æ¨èæ¨¡å‹
    class SimpleModel(nn.Module):
        def __init__(self, num_users, num_items, embed_dim):
            super().__init__()
            self.user_embedding = nn.Embedding(num_users, embed_dim)
            self.item_embedding = nn.Embedding(num_items, embed_dim)
            
        def forward(self, user_ids, item_ids):
            user_vecs = self.user_embedding(user_ids)
            item_vecs = self.item_embedding(item_ids)
            scores = torch.sum(user_vecs * item_vecs, dim=1)
            return scores
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = SimpleModel(num_users=100, num_items=50, embed_dim=32)
    optimizer = optim.Adam(model.parameters(), lr=0.01)
    criterion = nn.MSELoss()
    
    print(f"âœ… åˆ›å»ºæ¨èæ¨¡å‹")
    print(f"   ç”¨æˆ·æ•°: 100, ç‰©å“æ•°: 50, åµŒå…¥ç»´åº¦: 32")
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    batch_size = 16
    user_ids = torch.randint(0, 100, (batch_size,))
    item_ids = torch.randint(0, 50, (batch_size,))
    ratings = torch.rand(batch_size) * 5  # è¯„åˆ† 0-5
    
    print(f"\nğŸ“ è®­ç»ƒæ•°æ®ç¤ºä¾‹:")
    print(f"   æ‰¹å¤§å°: {batch_size}")
    print(f"   ç”¨æˆ·ID: {user_ids[:5].tolist()}")
    print(f"   ç‰©å“ID: {item_ids[:5].tolist()}")
    print(f"   è¯„åˆ†: {ratings[:5].tolist()}")
    
    # è®­ç»ƒå‰çš„åµŒå…¥å‘é‡
    initial_embedding = model.user_embedding.weight.data[0].clone()
    print(f"\nğŸ”„ è®­ç»ƒå‰ç”¨æˆ·0åµŒå…¥: {initial_embedding[:5].numpy()}")
    
    # è®­ç»ƒæ­¥éª¤
    for epoch in range(3):
        # å‰å‘ä¼ æ’­
        predictions = model(user_ids, item_ids)
        loss = criterion(predictions, ratings)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        print(f"   Epoch {epoch+1}: Loss = {loss.item():.4f}")
    
    # è®­ç»ƒåçš„åµŒå…¥å‘é‡
    final_embedding = model.user_embedding.weight.data[0]
    print(f"\nâœ… è®­ç»ƒåç”¨æˆ·0åµŒå…¥: {final_embedding[:5].numpy()}")
    
    # è®¡ç®—å˜åŒ–
    change = torch.norm(final_embedding - initial_embedding).item()
    print(f"   åµŒå…¥å‘é‡å˜åŒ–é‡: {change:.6f}")
    
    return model

def save_load_demo(user_embedding):
    """ä¿å­˜å’ŒåŠ è½½åµŒå…¥å‘é‡æ¼”ç¤º"""
    print(f"\nğŸ’¾ ä¿å­˜å’ŒåŠ è½½æ¼”ç¤º")
    print("=" * 50)
    
    # ä¿å­˜æ¨¡å‹
    torch.save(user_embedding.state_dict(), 'user_embedding.pth')
    print(f"âœ… åµŒå…¥å‘é‡å·²ä¿å­˜")
    
    # åŠ è½½æ¨¡å‹
    new_embedding = nn.Embedding(1000, 64)
    new_embedding.load_state_dict(torch.load('user_embedding.pth'))
    print(f"âœ… åµŒå…¥å‘é‡å·²åŠ è½½")
    
    # éªŒè¯
    test_id = torch.tensor([42])
    original = user_embedding(test_id)
    loaded = new_embedding(test_id)
    
    is_same = torch.allclose(original, loaded)
    print(f"âœ… éªŒè¯ç»“æœ: {'æˆåŠŸ' if is_same else 'å¤±è´¥'}")
    
    return new_embedding

def practical_example():
    """å®é™…ä½¿ç”¨ç¤ºä¾‹"""
    print(f"\nğŸ¯ å®é™…ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    # åˆ›å»ºç”¨æˆ·åµŒå…¥
    user_embedding = nn.Embedding(1000, 64)
    
    # æ¨¡æ‹Ÿå®é™…ç”¨æˆ·ID
    active_users = [15, 42, 88, 156, 299]
    user_ids = torch.tensor(active_users)
    
    # è·å–åµŒå…¥å‘é‡
    user_vectors = user_embedding(user_ids)
    
    print(f"æ´»è·ƒç”¨æˆ·: {active_users}")
    print(f"åµŒå…¥å‘é‡å½¢çŠ¶: {user_vectors.shape}")
    
    # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„ç”¨æˆ·
    target_user = 0  # ç›®æ ‡ç”¨æˆ·ç´¢å¼•
    target_vec = user_vectors[target_user]
    
    similarities = torch.cosine_similarity(
        target_vec.unsqueeze(0), 
        user_vectors
    )
    
    print(f"\nç”¨æˆ·{active_users[target_user]}ä¸å…¶ä»–ç”¨æˆ·çš„ç›¸ä¼¼åº¦:")
    for i, uid in enumerate(active_users):
        if i != target_user:
            print(f"   ç”¨æˆ·{uid}: {similarities[i].item():.4f}")
    
    # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„ç”¨æˆ·
    similarities[target_user] = -1  # æ’é™¤è‡ªå·±
    most_similar_idx = torch.argmax(similarities).item()
    
    print(f"\nğŸ” æœ€ç›¸ä¼¼çš„ç”¨æˆ·: {active_users[most_similar_idx]}")
    print(f"   ç›¸ä¼¼åº¦: {similarities[most_similar_idx].item():.4f}")
    
    return user_vectors

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ‰ PyTorchç”¨æˆ·IDåµŒå…¥å‘é‡ç”Ÿæˆ - ç®€æ´ç‰ˆ")
    print("=" * 80)
    
    # 1. åŸºç¡€æ¼”ç¤º
    user_embedding = basic_user_embedding_demo()
    
    # 2. è®­ç»ƒæ¼”ç¤º
    model = training_embedding_demo()
    
    # 3. ä¿å­˜åŠ è½½æ¼”ç¤º
    save_load_demo(user_embedding)
    
    # 4. å®é™…åº”ç”¨ç¤ºä¾‹
    practical_example()
    
    print(f"\n" + "=" * 80)
    print("ğŸ¯ æ ¸å¿ƒä»£ç æ¨¡æ¿:")
    print("""
# 1. åˆ›å»ºåµŒå…¥å±‚
user_embedding = nn.Embedding(num_users, embedding_dim)

# 2. è·å–åµŒå…¥å‘é‡
user_ids = torch.tensor([10, 20, 30])
user_vectors = user_embedding(user_ids)

# 3. è®¡ç®—ç›¸ä¼¼åº¦
similarity = torch.cosine_similarity(vec1, vec2, dim=0)

# 4. åœ¨æ¨¡å‹ä¸­ä½¿ç”¨
class RecommendModel(nn.Module):
    def __init__(self, num_users, embedding_dim):
        super().__init__()
        self.user_embedding = nn.Embedding(num_users, embedding_dim)
    
    def forward(self, user_ids):
        return self.user_embedding(user_ids)

# 5. è®­ç»ƒ
optimizer = optim.Adam(model.parameters(), lr=0.01)
loss.backward()
optimizer.step()
""")
    print("=" * 80)

if __name__ == "__main__":
    main() 