#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ‰æ„ä¹‰çš„ç”¨æˆ·IDåµŒå…¥å‘é‡è®­ç»ƒ
é€šè¿‡ç”¨æˆ·è¡Œä¸ºæ•°æ®å­¦ä¹ ç”¨æˆ·åå¥½çš„åµŒå…¥å‘é‡
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

class MeaningfulUserEmbedding:
    def __init__(self):
        self.num_users = 1000
        self.num_items = 500
        self.embedding_dim = 64
        
    def generate_user_behavior_data(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„ç”¨æˆ·è¡Œä¸ºæ•°æ®"""
        print("ğŸ“Š ç”Ÿæˆç”¨æˆ·è¡Œä¸ºæ•°æ®...")
        
        # è®¾ç½®éšæœºç§å­ä»¥è·å¾—å¯é‡å¤çš„ç»“æœ
        np.random.seed(42)
        
        # ç”Ÿæˆç”¨æˆ·-ç‰©å“äº¤äº’æ•°æ®
        num_interactions = 50000
        
        # åˆ›å»ºä¸€äº›æœ‰æ„ä¹‰çš„ç”¨æˆ·ç¾¤ä½“
        # ç”¨æˆ·0-299: å–œæ¬¢ç§‘æŠ€äº§å“ (ç‰©å“0-199)
        # ç”¨æˆ·300-599: å–œæ¬¢æ—¶å°šäº§å“ (ç‰©å“200-399)  
        # ç”¨æˆ·600-999: å–œæ¬¢è¿åŠ¨äº§å“ (ç‰©å“300-499)
        
        interactions = []
        
        # ç§‘æŠ€çˆ±å¥½è€…
        for _ in range(20000):
            user_id = np.random.randint(0, 300)
            item_id = np.random.randint(0, 200)  # åå¥½ç§‘æŠ€äº§å“
            rating = np.random.normal(4.0, 0.8)  # é«˜è¯„åˆ†
            rating = np.clip(rating, 1, 5)
            interactions.append([user_id, item_id, rating])
        
        # æ—¶å°šçˆ±å¥½è€…
        for _ in range(20000):
            user_id = np.random.randint(300, 600)
            item_id = np.random.randint(200, 400)  # åå¥½æ—¶å°šäº§å“
            rating = np.random.normal(4.2, 0.7)  # é«˜è¯„åˆ†
            rating = np.clip(rating, 1, 5)
            interactions.append([user_id, item_id, rating])
        
        # è¿åŠ¨çˆ±å¥½è€…
        for _ in range(10000):
            user_id = np.random.randint(600, 1000)
            item_id = np.random.randint(300, 500)  # åå¥½è¿åŠ¨äº§å“
            rating = np.random.normal(3.8, 0.9)  # è¾ƒé«˜è¯„åˆ†
            rating = np.clip(rating, 1, 5)
            interactions.append([user_id, item_id, rating])
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(interactions, columns=['user_id', 'item_id', 'rating'])
        
        print(f"âœ… ç”Ÿæˆäº† {len(df)} æ¡ç”¨æˆ·è¡Œä¸ºè®°å½•")
        print(f"   ç”¨æˆ·æ•°: {df['user_id'].nunique()}")
        print(f"   ç‰©å“æ•°: {df['item_id'].nunique()}")
        print(f"   å¹³å‡è¯„åˆ†: {df['rating'].mean():.2f}")
        
        # æ˜¾ç¤ºä¸åŒç”¨æˆ·ç¾¤ä½“çš„åå¥½
        print(f"\nç”¨æˆ·ç¾¤ä½“åˆ†æ:")
        print(f"  ç§‘æŠ€çˆ±å¥½è€… (ç”¨æˆ·0-299): ä¸»è¦è´­ä¹°ç‰©å“0-199")
        print(f"  æ—¶å°šçˆ±å¥½è€… (ç”¨æˆ·300-599): ä¸»è¦è´­ä¹°ç‰©å“200-399")
        print(f"  è¿åŠ¨çˆ±å¥½è€… (ç”¨æˆ·600-999): ä¸»è¦è´­ä¹°ç‰©å“300-499")
        
        return df
    
    def create_recommendation_model(self):
        """åˆ›å»ºæ¨èæ¨¡å‹"""
        class MatrixFactorization(nn.Module):
            def __init__(self, num_users, num_items, embedding_dim):
                super().__init__()
                # ç”¨æˆ·åµŒå…¥å±‚ - è¿™é‡Œçš„åµŒå…¥å‘é‡ä¼šå­¦ä¹ ç”¨æˆ·åå¥½
                self.user_embedding = nn.Embedding(num_users, embedding_dim)
                # ç‰©å“åµŒå…¥å±‚ - å­¦ä¹ ç‰©å“ç‰¹å¾
                self.item_embedding = nn.Embedding(num_items, embedding_dim)
                
                # åç½®é¡¹
                self.user_bias = nn.Embedding(num_users, 1)
                self.item_bias = nn.Embedding(num_items, 1)
                self.global_bias = nn.Parameter(torch.zeros(1))
                
                # åˆå§‹åŒ–å‚æ•°
                self._init_weights()
            
            def _init_weights(self):
                """åˆå§‹åŒ–æƒé‡"""
                nn.init.normal_(self.user_embedding.weight, std=0.1)
                nn.init.normal_(self.item_embedding.weight, std=0.1)
                nn.init.normal_(self.user_bias.weight, std=0.1)
                nn.init.normal_(self.item_bias.weight, std=0.1)
            
            def forward(self, user_ids, item_ids):
                # è·å–ç”¨æˆ·å’Œç‰©å“çš„åµŒå…¥å‘é‡
                user_vectors = self.user_embedding(user_ids)
                item_vectors = self.item_embedding(item_ids)
                
                # è®¡ç®—ç”¨æˆ·å’Œç‰©å“çš„ç›¸ä¼¼åº¦
                interaction = torch.sum(user_vectors * item_vectors, dim=1)
                
                # æ·»åŠ åç½®é¡¹
                user_bias = self.user_bias(user_ids).squeeze()
                item_bias = self.item_bias(item_ids).squeeze()
                
                # æœ€ç»ˆé¢„æµ‹è¯„åˆ†
                prediction = interaction + user_bias + item_bias + self.global_bias
                
                return prediction
        
        return MatrixFactorization(self.num_users, self.num_items, self.embedding_dim)
    
    def train_meaningful_embeddings(self, df):
        """è®­ç»ƒæœ‰æ„ä¹‰çš„ç”¨æˆ·åµŒå…¥å‘é‡"""
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒæœ‰æ„ä¹‰çš„ç”¨æˆ·åµŒå…¥å‘é‡...")
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        user_ids = torch.tensor(df['user_id'].values, dtype=torch.long)
        item_ids = torch.tensor(df['item_id'].values, dtype=torch.long)
        ratings = torch.tensor(df['rating'].values, dtype=torch.float32)
        
        # åˆ†å‰²è®­ç»ƒå’ŒéªŒè¯é›†
        train_indices, val_indices = train_test_split(
            range(len(df)), test_size=0.2, random_state=42
        )
        
        # åˆ›å»ºæ¨¡å‹
        model = self.create_recommendation_model()
        optimizer = optim.Adam(model.parameters(), lr=0.01)
        criterion = nn.MSELoss()
        
        print(f"æ¨¡å‹å‚æ•°:")
        print(f"  ç”¨æˆ·åµŒå…¥ç»´åº¦: {self.embedding_dim}")
        print(f"  ç‰©å“åµŒå…¥ç»´åº¦: {self.embedding_dim}")
        print(f"  æ€»å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        # è®­ç»ƒè¿‡ç¨‹
        model.train()
        for epoch in range(50):
            # è®­ç»ƒ
            train_user_ids = user_ids[train_indices]
            train_item_ids = item_ids[train_indices]
            train_ratings = ratings[train_indices]
            
            optimizer.zero_grad()
            predictions = model(train_user_ids, train_item_ids)
            loss = criterion(predictions, train_ratings)
            loss.backward()
            optimizer.step()
            
            # éªŒè¯
            if epoch % 10 == 0:
                model.eval()
                with torch.no_grad():
                    val_user_ids = user_ids[val_indices]
                    val_item_ids = item_ids[val_indices]
                    val_ratings = ratings[val_indices]
                    
                    val_predictions = model(val_user_ids, val_item_ids)
                    val_loss = criterion(val_predictions, val_ratings)
                    
                print(f"  Epoch {epoch:2d}: è®­ç»ƒæŸå¤±={loss.item():.4f}, éªŒè¯æŸå¤±={val_loss.item():.4f}")
                model.train()
        
        return model
    
    def analyze_learned_embeddings(self, model, df):
        """åˆ†æå­¦ä¹ åˆ°çš„ç”¨æˆ·åµŒå…¥å‘é‡"""
        print(f"\nğŸ” åˆ†æå­¦ä¹ åˆ°çš„ç”¨æˆ·åµŒå…¥å‘é‡...")
        
        # è·å–æ‰€æœ‰ç”¨æˆ·çš„åµŒå…¥å‘é‡
        all_user_ids = torch.arange(self.num_users)
        user_embeddings = model.user_embedding(all_user_ids)
        
        # åˆ†æä¸åŒç”¨æˆ·ç¾¤ä½“çš„ç›¸ä¼¼æ€§
        print(f"\nç”¨æˆ·ç¾¤ä½“å†…éƒ¨ç›¸ä¼¼æ€§åˆ†æ:")
        
        # ç§‘æŠ€çˆ±å¥½è€… (ç”¨æˆ·0-299)
        tech_users = torch.arange(0, 300)
        tech_embeddings = model.user_embedding(tech_users)
        tech_similarities = torch.cosine_similarity(
            tech_embeddings.unsqueeze(1), 
            tech_embeddings.unsqueeze(0), 
            dim=2
        )
        # æ’é™¤å¯¹è§’çº¿ï¼ˆè‡ªå·±å’Œè‡ªå·±çš„ç›¸ä¼¼åº¦ï¼‰
        tech_avg_sim = (tech_similarities.sum() - tech_similarities.trace()) / (300 * 299)
        print(f"  ç§‘æŠ€çˆ±å¥½è€…ç¾¤ä½“å†…å¹³å‡ç›¸ä¼¼åº¦: {tech_avg_sim.item():.4f}")
        
        # æ—¶å°šçˆ±å¥½è€… (ç”¨æˆ·300-599)
        fashion_users = torch.arange(300, 600)
        fashion_embeddings = model.user_embedding(fashion_users)
        fashion_similarities = torch.cosine_similarity(
            fashion_embeddings.unsqueeze(1), 
            fashion_embeddings.unsqueeze(0), 
            dim=2
        )
        fashion_avg_sim = (fashion_similarities.sum() - fashion_similarities.trace()) / (300 * 299)
        print(f"  æ—¶å°šçˆ±å¥½è€…ç¾¤ä½“å†…å¹³å‡ç›¸ä¼¼åº¦: {fashion_avg_sim.item():.4f}")
        
        # è¿åŠ¨çˆ±å¥½è€… (ç”¨æˆ·600-999)
        sport_users = torch.arange(600, 1000)
        sport_embeddings = model.user_embedding(sport_users)
        sport_similarities = torch.cosine_similarity(
            sport_embeddings.unsqueeze(1), 
            sport_embeddings.unsqueeze(0), 
            dim=2
        )
        sport_avg_sim = (sport_similarities.sum() - sport_similarities.trace()) / (400 * 399)
        print(f"  è¿åŠ¨çˆ±å¥½è€…ç¾¤ä½“å†…å¹³å‡ç›¸ä¼¼åº¦: {sport_avg_sim.item():.4f}")
        
        # åˆ†æè·¨ç¾¤ä½“ç›¸ä¼¼æ€§
        print(f"\nè·¨ç¾¤ä½“ç›¸ä¼¼æ€§åˆ†æ:")
        
        # ç§‘æŠ€ vs æ—¶å°š
        tech_fashion_sim = torch.cosine_similarity(
            tech_embeddings.mean(dim=0), 
            fashion_embeddings.mean(dim=0), 
            dim=0
        )
        print(f"  ç§‘æŠ€çˆ±å¥½è€… vs æ—¶å°šçˆ±å¥½è€…: {tech_fashion_sim.item():.4f}")
        
        # ç§‘æŠ€ vs è¿åŠ¨
        tech_sport_sim = torch.cosine_similarity(
            tech_embeddings.mean(dim=0), 
            sport_embeddings.mean(dim=0), 
            dim=0
        )
        print(f"  ç§‘æŠ€çˆ±å¥½è€… vs è¿åŠ¨çˆ±å¥½è€…: {tech_sport_sim.item():.4f}")
        
        # æ—¶å°š vs è¿åŠ¨
        fashion_sport_sim = torch.cosine_similarity(
            fashion_embeddings.mean(dim=0), 
            sport_embeddings.mean(dim=0), 
            dim=0
        )
        print(f"  æ—¶å°šçˆ±å¥½è€… vs è¿åŠ¨çˆ±å¥½è€…: {fashion_sport_sim.item():.4f}")
        
        return user_embeddings
    
    def demonstrate_recommendations(self, model, df):
        """æ¼”ç¤ºæ¨èæ•ˆæœ"""
        print(f"\nğŸ¯ æ¼”ç¤ºæ¨èæ•ˆæœ...")
        
        # é€‰æ‹©ä¸åŒç¾¤ä½“çš„ä»£è¡¨ç”¨æˆ·
        test_users = [50, 350, 650]  # ç§‘æŠ€ã€æ—¶å°šã€è¿åŠ¨çˆ±å¥½è€…å„ä¸€ä¸ª
        user_names = ["ç§‘æŠ€çˆ±å¥½è€…", "æ—¶å°šçˆ±å¥½è€…", "è¿åŠ¨çˆ±å¥½è€…"]
        
        for user_id, user_name in zip(test_users, user_names):
            print(f"\nğŸ‘¤ ç”¨æˆ·{user_id} ({user_name}):")
            
            # è·å–è¯¥ç”¨æˆ·çš„å†å²è¡Œä¸º
            #user_history = df[df['user_id'] == user_id]
            user_history = df.query('user_id == @user_id')
            if len(user_history) > 0:
                print(f"   å†å²è¡Œä¸º: å¯¹ç‰©å“ {user_history['item_id'].tolist()[:5]} çš„è¯„åˆ†")
            
            # ä¸ºè¯¥ç”¨æˆ·æ¨èç‰©å“
            user_tensor = torch.tensor([user_id])
            all_items = torch.arange(self.num_items)
            
            # è®¡ç®—å¯¹æ‰€æœ‰ç‰©å“çš„é¢„æµ‹è¯„åˆ†
            with torch.no_grad():
                user_repeated = user_tensor.repeat(self.num_items)
                predictions = model(user_repeated, all_items)
            
            # è·å–è¯„åˆ†æœ€é«˜çš„ç‰©å“
            top_items = torch.topk(predictions, k=5).indices.tolist()
            top_scores = torch.topk(predictions, k=5).values.tolist()
            
            print(f"   æ¨èç‰©å“: {top_items}")
            print(f"   é¢„æµ‹è¯„åˆ†: {[f'{score:.2f}' for score in top_scores]}")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“ æœ‰æ„ä¹‰çš„ç”¨æˆ·IDåµŒå…¥å‘é‡è®­ç»ƒç¤ºä¾‹")
    print("=" * 80)
    
    # åˆ›å»ºå®ä¾‹
    demo = MeaningfulUserEmbedding()
    
    # 1. ç”Ÿæˆç”¨æˆ·è¡Œä¸ºæ•°æ®
    df = demo.generate_user_behavior_data()
    
    # 2. è®­ç»ƒæœ‰æ„ä¹‰çš„åµŒå…¥å‘é‡
    model = demo.train_meaningful_embeddings(df)
    
    # 3. åˆ†æå­¦ä¹ åˆ°çš„åµŒå…¥å‘é‡
    user_embeddings = demo.analyze_learned_embeddings(model, df)
    
    # 4. æ¼”ç¤ºæ¨èæ•ˆæœ
    demo.demonstrate_recommendations(model, df)
    
    print(f"\n" + "=" * 80)
    print("ğŸ¯ å…³é”®æ´å¯Ÿ:")
    print("â€¢ ç”¨æˆ·IDåµŒå…¥å‘é‡åªæœ‰é€šè¿‡ç”¨æˆ·è¡Œä¸ºæ•°æ®è®­ç»ƒæ‰æœ‰æ„ä¹‰")
    print("â€¢ ç›¸ä¼¼åå¥½çš„ç”¨æˆ·ä¼šæœ‰ç›¸ä¼¼çš„åµŒå…¥å‘é‡")
    print("â€¢ åµŒå…¥å‘é‡æ•æ‰äº†ç”¨æˆ·çš„æ½œåœ¨åå¥½ç‰¹å¾")
    print("â€¢ è®­ç»ƒåçš„åµŒå…¥å‘é‡å¯ä»¥ç”¨äºä¸ªæ€§åŒ–æ¨è")
    print("â€¢ ä»…ä»…åŸºäºIDçš„éšæœºåµŒå…¥å‘é‡æ²¡æœ‰å®é™…æ„ä¹‰")
    print("=" * 80)

if __name__ == "__main__":
    main() 